avgcty = mean(cty),
sdcty = sd(cty),
maxhwy = max(hwy))
# Sumarizando os dados pela combinação da variáveis/fatores
ddply(data, .(manufacturer, drv),
summarize,
avgcty = mean(cty),
sdcty = sd(cty),
maxhwy = max(hwy))
# Perceba a diferença entre summarize e transform
ddply(data, .(drv), summarize, avgcty = mean(cty))
ddply(data, .(drv), transform, avgcty = mean(cty))
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
getwd()
# Carregando o dataset
df <- read.csv2("C:/Users/Lucas/Documents/R/Datasets/estudantes.csv")
# Explorando os dados
head(df)
View(df)
summary(df)
str(df)
any(is.na(df))
install.packages('ggthemes')
library(ggplot2)
library(ggthemes)
library(dplyr)
# Obtendo apenas as colunas numéricas
colunas_numerica <- sapply(df, is.numeric)
colunas_numericas
# Obtendo apenas as colunas numéricas
colunas_numericas <- sapply(df, is.numeric)
colunas_numericas
# Filtando as colunas numéricas para correlação
data_cor <- cor(df[, colunas_numericas])
data_cor
head(data_cor)
# Pacotes para visualizar a análise de correlação
install.packages(corrgram)
# Pacotes para visualizar a análise de correlação
install.packages('corrgram')
# Pacotes para visualizar a análise de correlação
install.packages('corrplot')
# Pacotes para visualizar a análise de correlação
library(corrplot)
library(corrgram)
# Criando um corrplot
corrplot(data_cor, method = 'color')
corrgram(df, order = TRUE, lower.panel = panel.shade, upper.panel = panel.pie, text.panel = panel.txt)
# Criando um histograma
ggplot(df, aes(x = G3)) +
geom_histogram(bins = 20,
alpha = 0.5, fill = 'blue') + theme_minimal()
# Instalando os pacotes
install.packages('caret')
install.packages('randomForest')
# Carregando os pacotesd
library(caret)
library(datasets)
# Usando o dataset mtcars
data(mtcars)
View(mtcars)
# Função do caret para divisão dos dados
split <- createDataPartition(y = mtcars$mpg, p = 0.7, list = FALSE)
# Criando dados de treino e de teste
dados_treino <- mtcars[split,]
dados_teste <- [-split,]
dados_teste <- mtcars[-split,]
# Treinando o modelo
names(getModelInfo())
# Regressão Linear
modelolm <- train(mpg~., data = dados_treino, method = lm)
# Regressão Linear
modelolm <- train(mpg~., data = dados_treino, method = 'lm')
# Regressão Logística
modelolm <- train(mpg~., data = dados_treino, method = 'glm')
# Random Forest
modelolm <- train(mpg~., data = dados_treino, method = 'rf')
# Resumo do modelo
summary(modelolm)
# Regressão Linear
modelolm <- train(mpg~., data = dados_treino, method = 'lm')
# Regressão Logística
modelolm2 <- train(mpg~., data = dados_treino, method = 'glm')
# Random Forest
modelolm3 <- train(mpg~., data = dados_treino, method = 'rf')
# Resumo do modelo
summary(modelolm)
# Ajustando o modelo
controle1 <- trainControl(method = 'cv', number = 10)
modelolm2 <- train(mpg ~ ., data = mtcars, method = 'lm', trControl = control1, metric = 'Rsquared')
# Resumo do modelo
summary(modelolm2)
# Coletando os resíduos
residuals <- resid(modelolm2)
# Previsões
predictedValues <- predict(modelolm)
plot(dados_treino$mpg, predictedValues)
# Previsões
predictedValues <- predict(modelolm2)
plot(dados_treino$mpg, predictedValues)
# Mostrando a importância das variáveis para a criação do modelo
varImp(modelolm2)
# Visualizando os clusters
install.packages("cluster")
# Variavel que controla a execucao do script
Azure <- FALSE
if(Azure){
source("src/Tools.R")
Bikes <- maml.mapInputPort(1)
Bikes$dteday <- set.asPOSIXct(Bikes)
}else{
source("Tools.R")
Bikes <- read.csv("bikes.csv", sep = ",", header = T, stringsAsFactors = F )
Bikes$dteday <- char.toPOSIXct(Bikes)
}
getwd()
if(Azure){
source("src/Tools.R")
Bikes <- maml.mapInputPort(1)
Bikes$dteday <- set.asPOSIXct(Bikes)
}else{
source("C:/Users/Lucas/Videos/Cursos/Formacao Cientista de Dados/04. Big Data Analytics com R e Microsoft Azure Machine Learning/09.01.01 Tools.R")
Bikes <- read.csv("bikes.csv", sep = ",", header = T, stringsAsFactors = F )
Bikes$dteday <- char.toPOSIXct(Bikes)
}
source("D:/Vídeos/Cursos/Formacao Cientista de Dados/04. Big Data Analytics com R e Microsoft Azure Machine Learning/09.01.01 Tools.R")
# Variavel que controla a execucao do script
Azure <- FALSE
# Execucao de acordo com o valor da variavel Azure
if(Azure){
source("src/Tools.R")
Bikes <- maml.mapInputPort(1)
Bikes$dteday <- set.asPOSIXct(Bikes)
}else{
source("D:/Vídeos/Cursos/Formacao Cientista de Dados/04. Big Data Analytics com R e Microsoft Azure Machine Learning/09.01.01 Tools.R")
Bikes <- read.csv("bikes.csv", sep = ",", header = T, stringsAsFactors = F )
Bikes$dteday <- char.toPOSIXct(Bikes)
}
# Variavel que controla a execucao do script
Azure <- FALSE
getwd()
# Execucao de acordo com o valor da variavel Azure
if(Azure){
source("D:/Vídeos/Cursos/Formacao Cientista de Dados/04. Big Data Analytics com R e Microsoft Azure Machine Learning/09.01.01 Tools.R")
Bikes <- maml.mapInputPort(1)
Bikes$dteday <- set.asPOSIXct(Bikes)
}else{
source("D:/Vídeos/Cursos/Formacao Cientista de Dados/04. Big Data Analytics com R e Microsoft Azure Machine Learning/09.01.01 Tools.R")
Bikes <- read.csv("bikes.csv", sep = ",", header = T, stringsAsFactors = F )
Bikes$dteday <- char.toPOSIXct(Bikes)
}
require(dplyr)
print("Dimensões do dataframe antes das operações de transformação:")
print(dim(Bikes))
getwd()
if(Azure){
source("D:/Vídeos/Cursos/Formacao Cientista de Dados/04. Big Data Analytics com R e Microsoft Azure Machine Learning/09.01.01 Tools.R")
Bikes <- maml.mapInputPort(1)
Bikes$dteday <- set.asPOSIXct(Bikes)
}else{
source("D:/Vídeos/Cursos/Formacao Cientista de Dados/04. Big Data Analytics com R e Microsoft Azure Machine Learning/09.01.01 Tools.R")
Bikes <- read.csv("C:/Users/Lucas/Documents/R/Datasets/bikes.csv", sep = ",", header = T, stringsAsFactors = F )
Bikes$dteday <- char.toPOSIXct(Bikes)
}
print("Dimensões do dataframe antes das operações de transformação:")
print(dim(Bikes))
# Filtrando o dataframe
Bikes <- Bikes %>% filter(cnt > 100)
print("Dimensões do dataframe após as operações de transformação:")
print(dim(Bikes))
# ggplot2
require(ggplot2)
qplot(dteday, cnt, data = subset(Bikes, hr == 9), geom = "line")
getwd()
df <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet1.csv")
View(df)
#dados_vendas %>% mutate(receita_liquida = UnitPrice - (UnitPrice * Discount))
dados_vendas$receitaLiquida <- dados_vendas$UnitPrice - (dados_vendas$UnitPrice * dados_vendas$Discount)
require(caret)
library(dplyr)
library(ggplot2)
library(lubridate)
library(h2o)
dados_vendas <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet1.csv", header = TRUE)
dados_consumidores <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet2.csv")
dados_lojas <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet3.csv")
dados_produto <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet4.csv")
# Organizando o data set de vendas
dados_vendas <- dados_vendas[,-c(1,2)]
colnames(dados_vendas)[1] <- "ID"
colnames(dados_vendas)[2] <- "ProductID"
colnames(dados_vendas)[3] <- "ClientID"
colnames(dados_vendas)[4] <- "Discount"
colnames(dados_vendas)[5] <- "UnitPrice"
colnames(dados_vendas)[6] <- "Qauntity"
colnames(dados_vendas)[7] <- "StoreID"
colnames(dados_vendas)[8] <- "Date"
dados_vendas <- dados_vendas[-c(1,2,3,4),]
dados_vendas$Date <- as.Date(dados_vendas$Date, "%m/%d/%Y")
dados_vendas$Qauntity <- as.numeric(dados_vendas$Qauntity)
dados_vendas2 <- as.data.frame(apply(dados_vendas, 2, function(x) as.numeric(gsub(",", ".", x))))
dados_vendas$Discount <- dados_vendas2$Discount
dados_vendas$UnitPrice <- dados_vendas2$UnitPrice
#Plot
venda_produto <- as.data.frame(table(dados_vendas$ProductID))
venda_produto$percentual <- (venda_produto$Freq / sum(venda_produto$Freq))*100
ggplot(venda_produto, aes(x=reorder(Var1, -percentual), y=percentual, fill = percentual)) +
geom_bar(stat="identity") +
labs(y='', x='Produtos', title = "Produtos mais comprado") +
scale_fill_continuous(name="Compras em %") +
theme_classic() +
scale_y_continuous(limits=c(0, 60)) +
theme(panel.background=element_blank())
dados_vendas$ano <- year(dados_vendas$Date)
dados_vendas$mes <- month(dados_vendas$Date)
count(dados_vendas, ano)
filter(dados_vendas, ano == 2019)
#dados_vendas %>% mutate(receita_liquida = UnitPrice - (UnitPrice * Discount))
dados_vendas$receitaLiquida <- dados_vendas$UnitPrice - (dados_vendas$UnitPrice * dados_vendas$Discount)
head(dados_vendas)
filter(dados_vendas, sum(receita_liquida), ano == 2019)
filter(dados_vendas, sum(receitaLiquida), ano == 2019)
sum(dados_vendas$receitaLiquida)
soma = sum(dados_vendas$receitaLiquida)
soma = soma / 12
soma
filter(dados_vendas, receitaLiquida:ano==2019)
filter(dados_vendas, receitaLiquida, ano==2019)
vendas2019 <- filter(dados_vendas, receitaLiquida & ano == 2019)
vendas2019 <- filter(dados_vendas, receitaLiquida & ano == 2019)
vendas2019 <- filter(dados_vendas, receitaLiquida & dados_vendas$ano == 2019)
head(dados_vendas)
dados_vendas$ano <- year(dados_vendas$Date)
View(dados_vendas)
View(dados_vendas)
dados_vendas$ano <- year(dados_vendas$Date)
library(lubridate)
dados_vendas$ano <- year(dados_vendas$Date)
dados_vendas$mes <- month(dados_vendas$Date)
dados_vendas$Date <- as.Date(dados_vendas$Date, "%m/%d/%Y")
dados_vendas$ano <- year(dados_vendas$Date)
dados_vendas$mes <- month(dados_vendas$Date)
library(lubridate)
dados_vendas$Date <- as.Date(dados_vendas$Date, "%m/%d/%Y")
dados_vendas$ano <- year(dados_vendas$Date)
library(dplyr)
library(lubridate)
dados_vendas$Date <- as.Date(dados_vendas$Date, "%m/%d/%Y")
dados_vendas$ano <- year(dados_vendas$Date)
require(caret)
library(dplyr)
library(ggplot2)
library(lubridate)
library(h2o)
require(caret)
library(dplyr)
library(ggplot2)
library(lubridate)
library(h2o)
dados_vendas <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet1.csv", header = TRUE)
dados_consumidores <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet2.csv")
dados_lojas <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet3.csv")
dados_produto <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet4.csv")
# Organizando o data set de vendas
dados_vendas <- dados_vendas[,-c(1,2)]
colnames(dados_vendas)[1] <- "ID"
colnames(dados_vendas)[2] <- "ProductID"
colnames(dados_vendas)[3] <- "ClientID"
colnames(dados_vendas)[4] <- "Discount"
colnames(dados_vendas)[5] <- "UnitPrice"
colnames(dados_vendas)[6] <- "Qauntity"
colnames(dados_vendas)[7] <- "StoreID"
colnames(dados_vendas)[8] <- "Date"
dados_vendas <- dados_vendas[-c(1,2,3,4),]
library(lubridate)
dados_vendas$Date <- as.Date(dados_vendas$Date, "%m/%d/%Y")
dados_vendas$Qauntity <- as.numeric(dados_vendas$Qauntity)
dados_vendas2 <- as.data.frame(apply(dados_vendas, 2, function(x) as.numeric(gsub(",", ".", x))))
View(dados_vendas2)
dados_vendas$Discount <- dados_vendas2$Discount
dados_vendas$UnitPrice <- dados_vendas2$UnitPrice
dados_vendas$ano <- year(dados_vendas$Date)
dados_vendas$mes <- month(dados_vendas$Date)
install.packages('lubridate')
install.packages("lubridate")
library(lubridate)
dados_vendas$Date <- as.Date(dados_vendas$Date, "%m/%d/%Y")
dados_vendas$Qauntity <- as.numeric(dados_vendas$Qauntity)
dados_vendas$ano <- year(dados_vendas$Date)
dados_vendas$mes <- month(dados_vendas$Date)
vendas2019 <- filter(dados_vendas, receitaLiquida & dados_vendas$ano == 2019)
vendas2019 <- filter(dados_vendas, dados_vendas$receitaLiquida & dados_vendas$ano == 2019)
vendas2019
sum(vendas2019)
vendas2019 <- sum(dados_vendas$receitaLiquida & dados_vendas$ano == 2019)
vendas2019
vendas2019 <- subset(dados_vendas, ano == 2019)
View(vendas2019)
#dados_vendas %>% mutate(receita_liquida = UnitPrice - (UnitPrice * Discount))
dados_vendas$receitaLiquida <- dados_vendas$UnitPrice - (dados_vendas$UnitPrice * dados_vendas$Discount)
vendas2019 <- subset(dados_vendas, ano == 2019)
View(vendas2019)
sum(vendas2019$receitaLiquida)
vendaLiquidaMensal <- sum(vendas2019$receitaLiquida) / 12
vendaLiquidaMensal
vendaLiquidaMensal <- sum(vendas2019$UnitPrice) / 12
vendaLiquidaMensal
mean(vendas2019)
mean(vendas2019$UnitPrice)
vendaLiquidaMensal
sd(vendas2019$UnitPrice)
sd(vendas2019$UnitPrice / 12)
median(vendas2019$UnitPrice)
median(vendas2019$UnitPrice / 12)
View(dados_vendas)
View(vendas2019)
dataVendas2019 <- c(vendas2019$UnitPrice, dados_vendas$Discount)
dataVendas2019 <- as.data.frame(c(vendas2019$UnitPrice, dados_vendas$Discount))
View(dataVendas2019)
dataVendas2019 <- as.data.frame(c(vendas2019$UnitPrice))
View(dataVendas2019)
mean(dataVendas2019)
media <- mean(dataVendas2019)
media <- mean(dataVendas2019$`c(vendas2019$UnitPrice))
media
media
dataVendas2019 <- as.data.frame(vendas2019$UnitPrice)
media <- mean(dataVendas2019)
media
dataVendas2019 <- as.data.frame(vendas2019$UnitPrice)
dataVendas2019 <- as.data.frame(vendas2019$UnitPrice)
View(dataVendas2019)
View(dataVendas2019)
View(dataVendas2019)
vendas2019 <- subset(dados_vendas, ano == 2019)
dataVendas2019 <- as.data.frame(vendas2019$UnitPrice)
View(dataVendas2019)
View(dataVendas2019)
View(dataVendas2019)
View(dataVendas2019)
View(dataVendas2019)
View(dataVendas2019)
View(dataVendas2019)
media
View(vendas2019)
head(dataVendas2019)
vendaLiquidaMensal <- sum(vendas2019$UnitPrice) / 12
head(dataVendas2019)
require(caret)
library(dplyr)
library(ggplot2)
library(lubridate)
library(h2o)
dados_vendas <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet1.csv", header = TRUE)
dados_consumidores <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet2.csv")
dados_lojas <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet3.csv")
dados_produto <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Base de Dados - Questionário.xlsx - Sheet4.csv")
dados_vendas <- dados_vendas[,-c(1,2)]
colnames(dados_vendas)[1] <- "ID"
colnames(dados_vendas)[2] <- "ProductID"
colnames(dados_vendas)[3] <- "ClientID"
colnames(dados_vendas)[4] <- "Discount"
colnames(dados_vendas)[5] <- "UnitPrice"
colnames(dados_vendas)[6] <- "Qauntity"
colnames(dados_vendas)[7] <- "StoreID"
colnames(dados_vendas)[8] <- "Date"
dados_vendas <- dados_vendas[-c(1,2,3,4),]
View(dados_vendas)
dados_vendas$Date <- as.Date(dados_vendas$Date, "%m/%d/%Y")
dados_vendas$Qauntity <- as.numeric(dados_vendas$Qauntity)
dados_vendas2 <- as.data.frame(apply(dados_vendas, 2, function(x) as.numeric(gsub(",", ".", x))))
dados_vendas$Discount <- dados_vendas2$Discount
dados_vendas$UnitPrice <- dados_vendas2$UnitPrice
dados_vendas$ano <- year(dados_vendas$Date)
install.packages('lubridate')
install.packages("lubridate")
library(lubridate)
dados_vendas$ano <- year(dados_vendas$Date)
dados_vendas$mes <- month(dados_vendas$Date)
hist(dados_vendas$StoreID)
hist(count(dados_vendas$StoreID)
hist(count(dados_vendas$StoreID))
hist(count(dados_vendas$StoreID))
plot(dados_vendas$StoreID)
ggplot(dados_vendas$StoreID)
#dados_vendas %>% mutate(receita_liquida = UnitPrice - (UnitPrice * Discount))
dados_vendas$receitaLiquida <- dados_vendas$UnitPrice - (dados_vendas$UnitPrice * dados_vendas$Discount)
dados_vendas %>% group_by(StoreID)
dados_vendas %>% group_by(StoreID)
library(dplyr)
dados_vendas %>% group_by(StoreID)
View(dados_vendas)
dados_vendas %>% group_by(StoreID) %>% summarise(total = n())
View(dados_vendas)
View(dados_lojas)
View(dados_vendas)
View(dados_lojas)
View(dados_produto)
vendas2019 <- subset(dados_vendas, ano == 2019)
plot(vendas2019$mes)
hist(vendas2019$mes)
getwd()
restaurantes <- read.csv('C:/Users/Lucas/Documents/R/Datasets/Restaurant-features.csv')
restaurantes <- read.csv('C:/Users/Lucas/Documents/R/Datasets/Restaurant-features.csv', sep = ',', header = T, stringAsFactors = F)
=
restaurantes <- read.csv('C:/Users/Lucas/Documents/R/Datasets/Restaurant-features.csv', sep = ',', header = T, stringAsFactors = F)
restaurantes <- read.csv('C:/Users/Lucas/Documents/R/Datasets/Restaurant-features.csv', sep = ",", header = T, stringAsFactors = F)
restaurantes <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Restaurant-features.csv", sep = ",", header = T, stringAsFactors = F)
restaurantes <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Restaurant-features.csv", sep = ",",quote = "\"", header = T, stringAsFactors = F)
restaurantes <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Restaurant-features.csv", header = T, stringAsFactors = F)
restaurantes <- read.csv("C:/Users/Lucas/Documents/R/Datasets/Restaurant-features.csv")
ratings <- read.csv('C:/Users/Lucas/Documents/R/DataSets/Restaurant-ratings.csv')
restaurantes <- restaurantes[restaurantes$franchise == 'f' & restaurantes$alcohol != 'No_Alcohol_Served',]
require(dplyr)
df <- as.data.frame(restaurantes %>%
inner_join(ratings, by = 'placeID') %>%
select(name, rating) %>%
group_by(name) %>%
summarize(avg_Rating = mean(rating)) %>%
arrange(desc(avg_Rating)))
df
knitr::opts_chunk$set(echo = TRUE)
# Criando e Avaliando o
install.packages('ROCR')
gc()
knitr::opts_chunk$set(echo = TRUE)
# Coletando dados
credit.df <- read.csv("credit_dataset.csv", header = TRUE, sep = ",")
## Convertendo as variáveis para o tipo fator (categórica)
to.factors <- function(df, variables){
for (variable in variables){
df[[variable]] <- as.factor(df[[variable]])
}
return(df)
}
## Normalização
scale.features <- function(df, variables){
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center=T, scale=T)
}
return(df)
}
# Normalizando as variáveis
numeric.vars <- c("credit.duration.months", "age", "credit.amount")
credit.df <- scale.features(credit.df, numeric.vars)
# variáveis do tipo fator
categorical.vars <- c('credit.rating', 'account.balance', 'previous.credit.payment.status',
'credit.purpose', 'savings', 'employment.duration', 'installment.rate',
'marital.status', 'guarantor', 'residence.duration', 'current.assets',
'other.credits', 'apartment.type', 'bank.credits', 'occupation',
'dependents', 'telephone', 'foreign.worker')
credit.df <- to.factors(df = credit.df, variables = categorical.vars)
# Dividindo os dados em treino e teste - 60:40 ratio
indexes <- sample(1:nrow(credit.df), size = 0.6 * nrow(credit.df))
train.data <- credit.df[indexes,]
test.data <- credit.df[-indexes,]
library(caret)
library(randomForest)
# Função para a seleção de variáveis
run.feature.selection <- function(num.iters=20, feature.vars, class.var){
set.seed(10)
variable.sizes <- 1:10
control <- rfeControl(functions = rfFuncs, method = "cv",
verbose = FALSE, returnResamp = "all",
number = num.iters)
results.rfe <- rfe(x = feature.vars, y = class.var,
sizes = variable.sizes,
rfeControl = control)
return(results.rfe)
}
# Executando a função
rfe.results <- run.feature.selection(feature.vars = train.data[,-1],
class.var = train.data[,1])
# Visualizando os resultados
rfe.results
varImp((rfe.results))
# Criando e Avaliando o modelo
library(caret)
library(ROCR)
# Biblioteca de utilitários para construção de gráficos
source("plot_utils.R")
## separate feature and class variables
test.feature.vars <- test.data[,-1]
test.class.var <- test.data[,1]
# Construindo um modelo de regressão logística
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
lr.model <- glm(formula = formula.init, data = train.data, family = "binomial")
# Visualizando o modelo
summary(lr.model)
# Testando o modelo nos dados de teste
lr.predictions <- predict(lr.model, test.data, type="response")
lr.predictions <- round(lr.predictions)
# Avaliando o modelo
confusionMatrix(data = lr.predictions, reference = test.class.var, positive = '1')
# Avaliando o modelo
confusionMatrix(data = lr.predictions, reference = test.class.var, positive = '1')
# Avaliando a performance do modelo
# Criando curvas ROC
lr.model.best <- lr.model
lr.prediction.values <- predict(lr.model.best, test.feature.vars, type = "response")
predictions <- prediction(lr.prediction.values, test.class.var)
par(mfrow = c(1,2))
plot.roc.curve(predictions, title.text = "Curva ROC")
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
gc()
setwd("C:/Users/Lucas/Documents/R/DSA - R/2 - Machine Learning/Classificação/")
# Carregando o dataset antes da transformação
df <- read.csv("German Credit Card UCI dataset.csv")
head(df)
str(df)
