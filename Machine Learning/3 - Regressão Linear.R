Sys.setlocale("LC_ALL","pt_BR.UTF-8")
## Regress√£oLinear


# Prevendo nota final dos alunos.


# Carregando o dataset
df <- read.csv2("C:/Users/Lucas/Documents/R/Datasets/estudantes.csv")


# Explorando os dados
head(df)
summary(df)
str(df)
any(is.na(df))


library(ggplot2)
library(ggthemes)
library(dplyr)

# Obtendo apenas as colunas numÈricas
colunas_numericas <- sapply(df, is.numeric)
colunas_numericas


# Filtrando as colunas numÈricas para correlaÁ„o
data_cor <- cor(df[, colunas_numericas])
data_cor
head(data_cor)

# Pacotes para visualizar a an√°lise de correlaÁ„o
library(corrplot)
library(corrgram)

# Criando um corrplot
corrplot(data_cor, method = 'color')

# Criando um corrgram
corrgram(df, order = TRUE, lower.panel = panel.shade, upper.panel = panel.pie, text.panel = panel.txt)

# Criando um histograma
ggplot(df, aes(x = G3)) + 
  geom_histogram(bins = 20,
                 alpha = 0.5, fill = 'blue') + theme_minimal()


# Treinando e Interpretando o Modelo
# Import Library
library(caTools)

# Criando as amostras de forma rand√¥mica
set.seed(101)
?sample.split
amostra <- sample.split(df$age, SplitRatio = 0.7)

# ***** Treinamos nosso modelo nos dados de treino *****
# ***** Fazemos as predi√ß√µes nos dados de teste *****

# Criando dados de treino - 70% dos dados
treino = subset(df, amostra == TRUE)

# Criando dados de teste - 30% dos dados
teste = subset(df, amostra == FALSE)

# Gerando o Modelo (Usando todas os atributos)
modelo_v1 <- lm(G3 ~ ., treino)
modelo_v2 <- lm(G3 ~ G2 + G1, treino)
modelo_v3 <- lm(G3 ~ absences, treino)
modelo_v4 <- lm(G3 ~ Medu, treino)


# Interpretando o modelo
summary(modelo_v1)
summary(modelo_v2)
summary(modelo_v3)
summary(modelo_v4)


# par(mfrow = c(2,2))
# plot(modelo_v3)

# ****************************************************
# *** Estas informacoes abaixo eh que farao de voc√É¬™ ***
# *** um verdadeiro conhecedor de Machine Learning ***
# ****************************************************

# Residuos
# Diferenca entre os valores observados de uma variavel e seus valores previstos
# Seus residuos devem se parecer com uma distribuicao normal, o que indica
# que a media entre os valores previstos e os valores observados eh proximo de 0 (o que eh bom)

# Coeficiente - Intercept - a (alfa)
# Valor de a na equa√ß√£o de Regress√£o

# Coeficiente - G2 - b (beta)
# Neste caso, o valor de G2 representa o valor de b na equa√ß√£o de Regress√£o

# Erro Padr√£o
# Medida de variabilidade na estimativa do coeficiente a (alfa). O ideal eh que este valor 
# seja menor que o valor do coeficiente, mas nem sempre isso ir√° ocorrer.

# Asteriscos 
# Os asteriscos representam os n√≠veis de significancia de acordo com o p-value.
# Quanto mais estrelas, maior a siginific√¢ncia.
# Atencao --> Muitos asteriscos indicam que eh improv√°vel que n√£o exista relacionamento entre as vari√°veis.

# Valor t
# Define se coeficiente da variavel eh significativo ou nao para o modelo. 
# Ele eh usado para calcular o p-value e os n√≠veis de signific√¢ncia.

# p-value
# O p-value representa a probabilidade que a vari√°vel n√£o seja relevante. 
# Deve ser o menor valor poss√≠vel. Se este valor for realmente pequeno, o R ira mostrar o valor como notacao cientifica

# Significancia
# S√£o aquelas legendas proximas as suas vari√°veis
# Espa√ßo em branco - ruim
# Pontos - razo√°vel
# Asteriscos - bom
# Muitos asteriscos - muito bom

# Residual Standar Error
# Este valor representa o desvio padr√£o dos res√≠duos

# Degrees of Freedom
# √â a diferenca entre o n√∫mero de observa√ß√µes na amostra de treinamento e o n√∫mero de vari√°veis no seu modelo

# R-squared
# Ajuda a avaliar o nivel de precisao do nosso modelo. Quanto maior, melhor, sendo 1 o valor ideal.

# F-statistics
# Eh o teste F do modelo. Esse teste obtem os parametros do nosso modelo e compara com um modelo que tenha menos parametros
# Em teoria, um modelo com mais parametros tem um desempenho melhor. Se o seu modelo com mais parametros NAO tiver perfomance
# melhor que um modelo com menos parametros, o valor do p-value sera bem alto. Se o modelo com mais parametros tem performance
# melhor que um modelo com menos parametros, o valor do p-value sera mais baixo.

# Lembre que correlacao nao implica causalidade


# visualizando o Modelo e Fazendo Previs√µes

# Obtendo res√≠duos
res <- residuals(modelo_v1)

# Convertendo o objeto para um dataframe
res <- as.data.frame(res)
head(res)

# Histograma dos res√≠duos
ggplot(res, aes(res)) +
  geom_histogram(fill = 'blue',
                 alpha = 0.5,
                 binwidth = 1)


# Plot do Modelo
# plot(modelo_v1)

# Fazendo as predi√ß√µes
prevendo_G3 <- predict(modelo_v1, teste)
prevendo_G3

# Visualizando os valores previstos e observados
resultados <- cbind(prevendo_G3, teste$G3)
colnames(resultados) <- c('Previsao', 'Real')
resultados <- as.data.frame(resultados)
resultados$Previsao <- round(resultados$Previsao)
resultados
min(resultados)

# Tratando os valores negativos
trata_zero <- function(x){
  if(x < 0){
    return(0)
  }else{
    return(x)
  }
}

# aplicando a fun√ß√£o para tratar valores negativos em nossa previs√£o
resultados$Previsao <- sapply(resultados$Previsao, trata_zero)
resultados


# Calculando o erro m√©dia
# Qu√£o distantes seus valores previstos est√£o dos valores observados
# MSE

mse <- mean((resultados$Real - resultados$Previsao)^2)
print(mse)


#RMSE
rmse <- mse^0.5
rmse

# Calculando R Squared
SSE = sum((resultados$Previsao - resultados$Real)^2)
SST = sum((mean(df$G3) - resultados$Real)^2)


# R-Squared
# AJuda a avaliar o n√≠vel de precis√£o do nosso modelo. Quanto mais pr√≥ximo de 1 melhor.
R2 = 1 - (SSE/SST)
R2
